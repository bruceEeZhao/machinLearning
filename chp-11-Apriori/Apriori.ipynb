{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. 使用Apriori算法进行关联分析\n",
    "\n",
    "从大规模数据集中寻找物品间的隐含关系被称为关联分析(association analysis)或者关联规则学习(association rule learning)。\n",
    "\n",
    "大规模数据的关系可以有两种形式：频繁项集和关联规则  \n",
    "- 频繁项集(frequent item sets)：经常出现在一起的物品的集合\n",
    "- 关联规则(association ruls)：暗示两种物品之间可能存在很强的关系\n",
    "\n",
    "**名词解释**  \n",
    "- 频繁模式(frequent patterns)：是一种在数据集中频繁出现的模式（例如 项集，子序列，子结构）。例如牛奶和面包在一组交易数据集合中频繁的出现，那么称牛奶和面包是频繁项集；子序列，例如先买电脑，之后买相机，之后买存储卡，若它在购买历史中频繁出现，那么它是一个频繁序列模式；子结构可以指不同的结构形式，如子图、子树或子格，它们可以与项集或子序列组合在一起。如果一个子结构频繁出现，它被称为(频繁的)结构化模式。\n",
    "\n",
    "\n",
    "- 支持度(support):数据集中包含该项集的记录所占的比例。从下面的例子中可以看出{豆奶}的支持度为4/5，{豆奶，尿布}的支持度为3/5。支持度是针对项集来说的，因此可以定义一个最小支持度，只保留满足最小支持度的项集。\n",
    "\n",
    "\n",
    "- 置信度(confidence):置信度是针对一条诸如{尿布}->{葡萄酒}的关联规则来定义的。这条规则的可信度定义为 **支持度({尿布，葡萄酒})/支持度({尿布})** 。以下面的数据为例，support({尿布，葡萄酒})=3/5， support({尿布})=4/5，所以confidence(尿布->葡萄酒)=3/4=0.75。这意味着对于包含“尿布”的所有记录，我们的规则对其75%的记录都适用。\n",
    "\n",
    "\n",
    "| 交易编号| 商品\n",
    "| ---| ---|\n",
    "| 0 | 豆奶，莴苣 |\n",
    "| 1 | 莴苣，尿布，葡萄酒，甜菜|\n",
    "| 2 | 豆奶， 尿布，葡萄酒，橙汁 | \n",
    "| 3 | 莴苣，豆奶，尿布，葡萄酒 |\n",
    "| 4 | 莴苣，豆奶，尿布，橙汁 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1. Apriori\n",
    "一个拥有N个物品的集合共有$2^N-1$种项集组合，所需的计算时间非常长。Apriori是为了解决这个问题而提出的算法。\n",
    "\n",
    "Apriori的原理是如果某个项集是频繁的，那么它的所有子集也是频繁的。如果一个项集是非频繁的，那么它的超集也是非频繁的。例如计算出项集{2,3}是非频繁的，那么就知道{0,2,3},{1,2,3},{0,1,2,3}也是非频繁的，就不在需要计算这些项集的支持度。使用该原理就可以避免项集数目的指数增长。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历数据集中的每一个交易，将单个的交易项组成一个集合（frozenset）\n",
    "# 这里需要注意的一点是：map在python2中返回一个列表，在python3中返回一个迭代器，因此这里需要将返回值转成list\n",
    "def createC1(dataSet):\n",
    "    C1 = []\n",
    "    for transaction in dataSet:\n",
    "        for item in transaction:\n",
    "            if not [item] in C1:\n",
    "                C1.append([item])\n",
    "    C1.sort()\n",
    "    return list(map(frozenset, C1))\n",
    "\n",
    "\n",
    "'''\n",
    "    参数： D:  数据集\n",
    "          Ck: 候选集列表\n",
    "          minSupport: 最小支持度\n",
    "          \n",
    "    返回值： retList: 满足最小支持度的项集列表\n",
    "            supportData：满足最小支持度的以项集为key，以支持度为value的字典\n",
    "'''\n",
    "def scanD(D, Ck, minSupport):\n",
    "    ssCnt = {}\n",
    "    # 对于数据集中的每一条记录\n",
    "    for tid in D:\n",
    "        # 对于候选项集中的每一项\n",
    "        for can in Ck:\n",
    "            # 如果该项集是记录的一个子集，则将字典中的记录+1\n",
    "            if can.issubset(tid):\n",
    "                if not ssCnt.get(can): ssCnt[can] = 1\n",
    "                else: ssCnt[can] += 1\n",
    "                    \n",
    "    numItems = float(len(D))\n",
    "    retList = []\n",
    "    supportData = {}\n",
    "    for key in ssCnt:\n",
    "        support = ssCnt[key]/numItems\n",
    "        # 如果支持度大于最小支持度，则加入结果列表中\n",
    "        if support >= minSupport:\n",
    "            retList.insert(0,key)\n",
    "        supportData[key] = support\n",
    "    return retList, supportData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({1}),\n",
       " frozenset({2}),\n",
       " frozenset({3}),\n",
       " frozenset({4}),\n",
       " frozenset({5})]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet = [[1,3,4], [2,3,5], [1,2,3,5], [2,5]]\n",
    "C1 = createC1(dataSet)\n",
    "C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = list(map(set, dataSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([frozenset({1}), frozenset({3}), frozenset({2}), frozenset({5})],\n",
       " {frozenset({4}): 0.25,\n",
       "  frozenset({5}): 0.75,\n",
       "  frozenset({2}): 0.75,\n",
       "  frozenset({3}): 0.75,\n",
       "  frozenset({1}): 0.5})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanD(D, C1, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2. Apriori算法\n",
    "\n",
    "\n",
    "伪代码如下：\n",
    "```\n",
    "当集合中项的个数大于0时\n",
    "    构建一个k个项组成的候选项集的列表\n",
    "    检查数据以确认每个项集都是频繁的\n",
    "    保留频繁项集并构建k+1项组成的候选集的列表\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    参数： Lk: 频繁项集列表\n",
    "           k: 将要生成的项集元素个数\n",
    "           \n",
    "    k-2 保证了相对于上一次的项集，这次生成的项集会多一位数字\n",
    "           \n",
    "    以 Lk = {0} {1} {2}, k=2 举例:\n",
    "        k-2 = 0\n",
    "        L1 = []\n",
    "        L2 = []\n",
    "        retList = [{0,1}, {0,2}, {1,2}]\n",
    "'''\n",
    "def aprioriGen(Lk, k):\n",
    "    retList = []\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i+1, lenLk):\n",
    "            L1 = list(Lk[i])[:k-2]\n",
    "            L2 = list(Lk[j])[:k-2]\n",
    "            L1.sort()\n",
    "            L2.sort()\n",
    "            if L1 == L2:\n",
    "                retList.append(Lk[i] | Lk[j])\n",
    "    return retList\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "def apriori(dataSet, minSupport = 0.5):\n",
    "    C1 = createC1(dataSet)\n",
    "    D = list(map(set, dataSet))\n",
    "    L1, supportData = scanD(D, C1, minSupport)\n",
    "    L = [L1]\n",
    "    k = 2\n",
    "    while (len(L[k-2]) > 0):\n",
    "        Ck = aprioriGen(L[k-2], k)\n",
    "        Lk, supK = scanD(D, Ck, minSupport)\n",
    "        supportData.update(supK)\n",
    "        L.append(Lk)\n",
    "        k += 1\n",
    "    return L, supportData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, supportData = apriori(dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[frozenset({1}), frozenset({3}), frozenset({2}), frozenset({5})],\n",
       " [frozenset({3, 5}), frozenset({1, 3}), frozenset({2, 5}), frozenset({2, 3})],\n",
       " [frozenset({2, 3, 5})],\n",
       " []]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({5}): 0.75,\n",
       " frozenset({3}): 0.75,\n",
       " frozenset({2, 3, 5}): 0.5,\n",
       " frozenset({1, 2}): 0.25,\n",
       " frozenset({1, 5}): 0.25,\n",
       " frozenset({3, 5}): 0.5,\n",
       " frozenset({4}): 0.25,\n",
       " frozenset({2, 3}): 0.5,\n",
       " frozenset({2, 5}): 0.75,\n",
       " frozenset({1}): 0.5,\n",
       " frozenset({1, 3}): 0.5,\n",
       " frozenset({2}): 0.75}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supportData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3. 从频繁项集中挖掘关联规则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    作用: 主函数，调用下面两个函数\n",
    "    参数: L: 频繁项集列表\n",
    "         supportData: 满足最小支持度的以项集为key，以支持度为value的字典\n",
    "         minConfi: 最小可信度阈值\n",
    "    返回值: bigRuleList: 包含可信度的规则列表\n",
    "'''\n",
    "def generateRules(L, supportData, minConf=0.7):\n",
    "    bigRuleList = []\n",
    "    # 只获取两个或更多元素的集合，因为无法从单个元素项集中构建关联规则\n",
    "    for i in range(1, len(L)):\n",
    "        for freqSet in L[i]:\n",
    "            H1 = [frozenset([item]) for item in freqSet]\n",
    "            # 如果项集中只有两个元素则直接通过calcConf计算\n",
    "            if i>1:\n",
    "                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "            else:\n",
    "                calcConf(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "                \n",
    "    return bigRuleList\n",
    "\n",
    "'''\n",
    "    作用： 对规则进行评估\n",
    "    参数: freqSet: 频繁项集\n",
    "         H: 只包含单个元素的集合列表\n",
    "         supportData:\n",
    "         br1:\n",
    "         minconf:\n",
    "         \n",
    "    返回值: prunedH: 满足最小可信度的规则列表\n",
    "    \n",
    "'''\n",
    "def calcConf(freqSet, H, supportData, br1, minConf=0.7):\n",
    "    prunedH = []\n",
    "    for conseq in H:\n",
    "        conf = supportData[freqSet]/supportData[freqSet-conseq]\n",
    "        if conf >= minConf:\n",
    "            print(freqSet-conseq,\"--->\",conseq, \"conf:\",conf)\n",
    "                br1.append((freqSet-conseq, conseq, conf))\n",
    "            prunedH.append(conseq)\n",
    "    return prunedH\n",
    "            \n",
    "'''\n",
    "    作用: 生成候选规则集合\n",
    "    参数: freqSet:\n",
    "         H:\n",
    "         supportData:\n",
    "         br1:\n",
    "         minconf:\n",
    "'''\n",
    "def rulesFromConseq(freqSet, H, supportData, br1, minConf):\n",
    "    m = len(H[0])\n",
    "    if (len(freqSet) > (m+1)):\n",
    "        Hmp1 = aprioriGen(H, m+1)\n",
    "        Hmp1 = calcConf(freqSet, Hmp1, supportData, br1, minConf)\n",
    "        if (len(Hmp1) > 1):\n",
    "            rulesFromConseq(freqSet, Hmp1, supportData, br1, minConf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({1}) ---> frozenset({3}) conf: 1.0\n",
      "frozenset({5}) ---> frozenset({2}) conf: 1.0\n",
      "frozenset({2}) ---> frozenset({5}) conf: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(frozenset({1}), frozenset({3}), 1.0),\n",
       " (frozenset({5}), frozenset({2}), 1.0),\n",
       " (frozenset({2}), frozenset({5}), 1.0)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateRules(L, supportData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({5}) ---> frozenset({3}) conf: 0.6666666666666666\n",
      "frozenset({3}) ---> frozenset({5}) conf: 0.6666666666666666\n",
      "frozenset({3}) ---> frozenset({1}) conf: 0.6666666666666666\n",
      "frozenset({1}) ---> frozenset({3}) conf: 1.0\n",
      "frozenset({5}) ---> frozenset({2}) conf: 1.0\n",
      "frozenset({2}) ---> frozenset({5}) conf: 1.0\n",
      "frozenset({3}) ---> frozenset({2}) conf: 0.6666666666666666\n",
      "frozenset({2}) ---> frozenset({3}) conf: 0.6666666666666666\n",
      "frozenset({5}) ---> frozenset({2, 3}) conf: 0.6666666666666666\n",
      "frozenset({3}) ---> frozenset({2, 5}) conf: 0.6666666666666666\n",
      "frozenset({2}) ---> frozenset({3, 5}) conf: 0.6666666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(frozenset({5}), frozenset({3}), 0.6666666666666666),\n",
       " (frozenset({3}), frozenset({5}), 0.6666666666666666),\n",
       " (frozenset({3}), frozenset({1}), 0.6666666666666666),\n",
       " (frozenset({1}), frozenset({3}), 1.0),\n",
       " (frozenset({5}), frozenset({2}), 1.0),\n",
       " (frozenset({2}), frozenset({5}), 1.0),\n",
       " (frozenset({3}), frozenset({2}), 0.6666666666666666),\n",
       " (frozenset({2}), frozenset({3}), 0.6666666666666666),\n",
       " (frozenset({5}), frozenset({2, 3}), 0.6666666666666666),\n",
       " (frozenset({3}), frozenset({2, 5}), 0.6666666666666666),\n",
       " (frozenset({2}), frozenset({3, 5}), 0.6666666666666666)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateRules(L, supportData, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4. 发现毒蘑菇的相似特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mushroomdf = pd.read_csv(\"mushroom.dat\", sep=' ', header=None)\n",
    "mushroomdf = [line.split() for line in open('mushroom.dat').readlines()]\n",
    "L, supportData = apriori(np.array(mushroomdf), minSupport=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in L[1]:\n",
    "    if item.intersection('2.0'): print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[frozenset({2.0, 76.0}), frozenset({3.0, 86.0}), frozenset({59.0, 53.0}), frozenset({59.0, 76.0}), frozenset({116.0, 85.0}), frozenset({90.0, 67.0}), frozenset({94.0, 86.0}), frozenset({39.0, 23.0}), frozenset({85.0, 110.0}), frozenset({36.0, 63.0}), frozenset({36.0, 93.0}), frozenset({59.0, 39.0}), frozenset({10.0, 34.0}), frozenset({56.0, 85.0}), frozenset({90.0, 38.0}), frozenset({53.0, 94.0}), frozenset({85.0, 93.0}), frozenset({86.0, 63.0}), frozenset({85.0, 94.0}), frozenset({36.0, 110.0}), frozenset({90.0, 85.0}), frozenset({93.0, 39.0}), frozenset({63.0, 39.0}), frozenset({116.0, 36.0}), frozenset({24.0, 34.0}), frozenset({1.0, 85.0}), frozenset({67.0, 93.0}), frozenset({3.0, 85.0}), frozenset({34.0, 59.0}), frozenset({2.0, 86.0}), frozenset({90.0, 39.0}), frozenset({34.0, 3.0}), frozenset({10.0, 86.0}), frozenset({59.0, 86.0}), frozenset({2.0, 59.0}), frozenset({10.0, 36.0}), frozenset({24.0, 85.0}), frozenset({90.0, 6.0}), frozenset({85.0, 63.0}), frozenset({34.0, 85.0}), frozenset({90.0, 110.0}), frozenset({67.0, 36.0}), frozenset({93.0, 86.0}), frozenset({24.0, 90.0}), frozenset({67.0, 86.0}), frozenset({34.0, 28.0}), frozenset({52.0, 85.0}), frozenset({90.0, 3.0}), frozenset({36.0, 39.0}), frozenset({28.0, 39.0}), frozenset({110.0, 86.0}), frozenset({2.0, 39.0}), frozenset({59.0, 85.0}), frozenset({76.0, 85.0}), frozenset({86.0, 6.0}), frozenset({85.0, 86.0}), frozenset({90.0, 63.0}), frozenset({36.0, 6.0}), frozenset({36.0, 85.0}), frozenset({10.0, 90.0}), frozenset({34.0, 38.0}), frozenset({53.0, 63.0}), frozenset({90.0, 23.0}), frozenset({2.0, 90.0}), frozenset({85.0, 23.0}), frozenset({85.0, 39.0}), frozenset({59.0, 23.0}), frozenset({1.0, 34.0}), frozenset({56.0, 39.0}), frozenset({2.0, 23.0}), frozenset({59.0, 36.0}), frozenset({90.0, 59.0}), frozenset({90.0, 116.0}), frozenset({76.0, 63.0}), frozenset({34.0, 52.0}), frozenset({2.0, 63.0}), frozenset({9.0, 85.0}), frozenset({34.0, 36.0}), frozenset({34.0, 67.0}), frozenset({24.0, 36.0}), frozenset({34.0, 23.0}), frozenset({38.0, 86.0}), frozenset({10.0, 85.0}), frozenset({53.0, 85.0}), frozenset({24.0, 86.0}), frozenset({59.0, 63.0}), frozenset({67.0, 63.0}), frozenset({63.0, 23.0}), frozenset({34.0, 110.0}), frozenset({28.0, 63.0}), frozenset({76.0, 86.0}), frozenset({28.0, 86.0}), frozenset({1.0, 36.0}), frozenset({2.0, 93.0}), frozenset({28.0, 85.0}), frozenset({67.0, 53.0}), frozenset({85.0, 38.0}), frozenset({36.0, 53.0}), frozenset({90.0, 36.0}), frozenset({28.0, 53.0}), frozenset({56.0, 116.0}), frozenset({90.0, 94.0}), frozenset({76.0, 53.0}), frozenset({59.0, 28.0}), frozenset({90.0, 53.0}), frozenset({56.0, 36.0}), frozenset({67.0, 76.0}), frozenset({24.0, 39.0}), frozenset({76.0, 93.0}), frozenset({56.0, 86.0}), frozenset({56.0, 90.0}), frozenset({34.0, 63.0}), frozenset({2.0, 34.0}), frozenset({76.0, 39.0}), frozenset({34.0, 86.0}), frozenset({34.0, 6.0}), frozenset({52.0, 39.0}), frozenset({59.0, 67.0}), frozenset({86.0, 39.0}), frozenset({53.0, 110.0}), frozenset({85.0, 6.0}), frozenset({2.0, 85.0}), frozenset({36.0, 86.0}), frozenset({52.0, 86.0}), frozenset({90.0, 52.0}), frozenset({36.0, 76.0}), frozenset({34.0, 116.0}), frozenset({1.0, 86.0}), frozenset({2.0, 53.0}), frozenset({90.0, 28.0}), frozenset({56.0, 34.0}), frozenset({90.0, 76.0}), frozenset({36.0, 52.0}), frozenset({24.0, 1.0}), frozenset({53.0, 86.0}), frozenset({58.0, 85.0}), frozenset({90.0, 86.0}), frozenset({1.0, 110.0}), frozenset({2.0, 67.0}), frozenset({34.0, 90.0}), frozenset({36.0, 23.0}), frozenset({24.0, 94.0}), frozenset({34.0, 39.0}), frozenset({67.0, 85.0}), frozenset({34.0, 94.0}), frozenset({53.0, 39.0}), frozenset({3.0, 39.0}), frozenset({86.0, 23.0}), frozenset({34.0, 93.0}), frozenset({116.0, 86.0}), frozenset({2.0, 28.0}), frozenset({67.0, 39.0}), frozenset({1.0, 90.0}), frozenset({34.0, 76.0}), frozenset({90.0, 93.0}), frozenset({24.0, 53.0}), frozenset({3.0, 36.0}), frozenset({24.0, 110.0}), frozenset({59.0, 93.0}), frozenset({93.0, 23.0}), frozenset({34.0, 53.0}), frozenset({2.0, 36.0}), frozenset({93.0, 63.0})]\n"
     ]
    }
   ],
   "source": [
    "print(L[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
