{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. support vector machines\n",
    "给定训练集样本 $D=\\{(x_1,y_1),(x_2,y_2),...(x_m,y_m)\\}, y\\in\\{-1,+1\\}$,分类学习最基本的想法就是基于训练集D在样本空间中找到一个划分超平面，将不同类别的样本分开。由于数据点都在二维平面上，所以此时分割超平面就是一个平面。更高维的情况可以以此类推。如果数据集是三维的，那么此时用来分割数据的就是一个平面。超平面也就是分类的决策边界，分布在超平面一侧的所有数据都数以某个分类，另一侧的数据则属于另一个类别。\n",
    "\n",
    "如果数据点离决策越远，那么其最后的预测结果也就越可信。我们希望找到离分割超平面最近的点，确保他们离分隔超平面的距离尽可能的大。这里点到分隔面的距离被称为间隔。\n",
    "\n",
    "支持向量（support vector）就是离分隔超平面最近的那些点。\n",
    "\n",
    "在样本空间中，分隔超平面可以用如下的线性方程来描述$w^Tx+b=0$，其中$w = (w_1;w_2....;w_d)$为法向量，决定了超平面的方向；b为位移项，决定了超平面与原点之间的距离。显然超平面可以被法向量w和位移b确定，将其记为$(w,b)$，样本空间中任一点x到超平面$(w,b)$的距离可写为$r = \\frac{||w^TA+b||}{||w||}$。\n",
    "\n",
    "假设超平面$(w,b)$能将训练样本正确分类，即对$(x_i,y_i)\\in D$若$y_i=+1$，则有\n",
    "\n",
    "$\\begin{cases}\n",
    "w^Tx_i+b\\ge+1, y_i=+1\\\\\n",
    "w^Tx_i+b\\le-1,y_i=-1\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "![svm.png](svm.png)\n",
    "\n",
    "如图所示，距离超平面最近的这几个训练样本点使等号成立，他们被称为“支持向量”两个异类支持向量到超平面的距离之和为$r = \\frac{2}{||w||}$，他被称为“间隔”。欲找到具有“最大间隔”(maximum margin)的划分超平面，也就是要找到能满足式中约束的参数$w$和$b$使得r最大，即\n",
    "\n",
    "$\n",
    "\\max\\limits_{w,1}\\frac{2}{||w||} \\\\\n",
    "s.t. \\qquad y_i(w^Tx_i+b)\\ge1, i = 1,2,...m\n",
    "$\n",
    "\n",
    "为了最大化间隔，仅需最大化$||w||^-1$，这个等价于最小化$||w||$于是可重写为：\n",
    "\n",
    "$\n",
    "\\min\\limits_{w,b} \\frac{1}{2}||w||^2 \\\\\n",
    "s.t. \\qquad y_i(w^Tx_i+b)\\ge1, i=1,2,...m\n",
    "$\n",
    "\n",
    "这就是支持向量机的基本型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简化版的SMO算法：\n",
    "\n",
    "platt SMO算法中的外驯化确定要优化的最佳alpha对。而简化版的却会跳过这一部分，首先在数据集上遍历每一个alpha，然后在剩下的alpha集合中随机选择另一个alpha，从而构架alpha对。这里有一点相当重要，就是要同时改变两个alpha。之所以这样做是因为有一个约束条件：$\\sum a_i \\cdot label^{(i)}=0$由于改变一个alpha可能会导致该约束条件失效，因此总是同时改变这两个alpha。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "'''从某个范围内随机选择一个整数\n",
    "    i : alpha的下标\n",
    "    m : 所有alpha的数目\n",
    "\n",
    "'''\n",
    "def selectJrand(i,m):\n",
    "    j=i\n",
    "    while (j==i):\n",
    "        j = int(random.uniform(0,m))\n",
    "    return j\n",
    "\n",
    "\n",
    "# 在数值过大时对其进行调整，确保aj在high和low之间\n",
    "def clipAlpha(aj, H, L):\n",
    "    if aj > H:\n",
    "        aj = H\n",
    "    if L > aj:\n",
    "        aj = L\n",
    "    return ajf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMO函数的伪代码大致如下：\n",
    "```\n",
    "创建一个alpha向量并将其初始化为0向量\n",
    "当迭代次数小于最大迭代次数时（外循环）\n",
    "    对数据集中的每个数据向量（内循环）：\n",
    "        如果该数据向量可以被优化：\n",
    "            随机选择另一个数据向量\n",
    "            同时优化这两个向量\n",
    "            如果两个向量都不能被优化，退出内循环\n",
    "    如果所有向量都没被优化，增加迭代数目，继续下一次循环\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    参数： dataMatIn: 数据集\n",
    "          classLabels: 标签\n",
    "          C :常数C\n",
    "          toler: 容错率\n",
    "          maxIter： 最大循环次数\n",
    "    \n",
    "    返回值： b,alpha \n",
    "'''\n",
    "\n",
    "def smoSimple(dataMatIn, classLabels, C: int, toler: float, maxIter: int):\n",
    "    dataMatrix = np.mat(dataMatIn)\n",
    "    labelMatrix = np.mat(classLabels).transpose()\n",
    "    # w^Tx+b确定一个超平面\n",
    "    b = 0\n",
    "    m,n = shape(dataMatrix)\n",
    "    alphas = np.mat(zeros((m,1)))\n",
    "    iternum = 0\n",
    "    \n",
    "    while(iternum < maxIter):\n",
    "        alphaPairsChanged = 0\n",
    "        for i in range(m):\n",
    "            # multiply数组和矩阵对应位置相乘，输出与相乘数组/矩阵的大小一致\n",
    "            # alphas m*1 转置之后 1*m\n",
    "            # dataMatrix[i,:] 是取第i行 1*n 转置之后是 n*1,dataMatrix是m*n 两者相乘是m*1\n",
    "            # fXi 是由1×m和m*1两个向量相乘而来，是一个常数\n",
    "            fXi = float(np.multiply(alphas, labelMatrix).T*(dataMatrix*dataMatrix[i,:].T))+b\n",
    "            Ei = fXi - float(labelMatrix[i])\n",
    "            if ((labelMatrix[i]*Ei < -toler) and (alphas[i] < C)) or \n",
    "            ((labelMatrix[i]*Ei > toler) and (alphas[i]>0)):\n",
    "                j = selectJrand(i,m)\n",
    "                fXj = float(np.multiply(alphas,labelMatrix).T*(dataMatrix*dataMatrix[j,:].T))+b\n",
    "                Ej = fXj - float(labelMatrix[j])\n",
    "                alphaIold = alphas[i].copy()\n",
    "                alphaJold = alphas[j].copy()\n",
    "                if (labelMatrix[i]!=labelMatrix[j]):\n",
    "                    L = max(0, alphas[j] - alphas[i])\n",
    "                    H = min(C, C + alphas[j] - aplhas[i])\n",
    "                else:\n",
    "                    L = max(0, alphas[j] + alphas[i] - C)\n",
    "                    H = min(C, alphas[j] + alphas[i])\n",
    "                if L==H: print(\"L==H\");continue\n",
    "                eta = 2.0 * dataMatrix[i,:]*dataMatrix[j,:].T - \\\n",
    "                    dataMatrix[i,:]*dataMatrix[i,:].T - \\\n",
    "                    dataMatrix[j.:]*dataMatrix[j,:].T\n",
    "                if eta>=0: print(\"eta>=0\");continue\n",
    "                alphas[j] -= labelMatrix[j]*(Ei - Ej)/eta\n",
    "                alphas[j] = clipAlpha(alphas[j], H, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
