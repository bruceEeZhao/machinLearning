{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 贝叶斯分类器\n",
    "\n",
    "计算后验概率 $P(c|x)$大体有两种策略：给定x，可通过直接建模 $P(c|x)$来预测c，这样得到的是“判别式模型”(discriminative models)；也可先对联合概率分布$P(x|c)$建模，然后再由此获得$P(c|x)$，这样得到的是“生成式模型”(generative models)。决策树，BP神经网络，支持向量机等，都可归入到判别式模型的范畴，对生成式模型来说 $P(c|x)=\\frac{P(x,c)}{P(x)}$，基于贝叶斯定理，$P(c|x)$可以写为  \n",
    "$P(c|x) = \\frac{P(c)P(x|c)}{P(x)}$  \n",
    "\n",
    "其中P(c)是类先验概率；P(x|c)是样本x在类标记c的条件下的条件概率，或称为“似然”；P(x)是用于归一化的“证据因子”。对给定样本x，证据因子P(x)与类标记无关，因此估计$P(c|x)$的问题就转化成为如何基于训练数据D来估计先验$P(c)$和似然$P(x|c)$\n",
    "\n",
    "基于贝叶斯公式来估计后验概率$P(c|x)$的主要困难在于：类条件概率$P(x|c)$是所有属性上的联合概率，难以从有限的训练样本直接估计而得。为避开这个障碍，朴素贝叶斯分类器采用了“属性条件独立性假设”对一直类别，假设所有属性相互独立。换言之，假设每个属性独立地对分类结果发生影响。基于属性条件独立性假设，贝叶斯公式可重写为：\n",
    "\n",
    "$P(c|x)=\\frac{P(c)P(x|c)}{P(x)}=\\frac{P(c)}{P(x)}\\prod_{i=1}^dP(x^i|c)$\n",
    "\n",
    "其中d为属性数目，$x_i$为x在第i个属性上的取值。\n",
    "\n",
    "朴素贝叶斯分类器的训练过程就是基于训练集D来估计类先验概率P(c)，并为每个属性估计条件概率$P(x_i|c)$\n",
    "\n",
    "令$D_c$表示训练集D中第c类样本组成的集合，若有充足的独立同分布样本，则可容易地估计出先验概率$P(c)=\\frac{|D_C|}{|D|}$，\n",
    "\n",
    "对离散属性而言，令$D_{c,x_i}$表示$D_c$中在第i个属性上取值为$x_i$的样本组成的集合，则条件概率$P(x_i|c)$可估计为$P(x_i|c)=\\frac{|D_{c,x_i}|}{|D_c|}$\n",
    "\n",
    "对连续属性可考虑概率密度函数，假定$p(x_i|c)\\approx N(\\mu_{c,i},\\sigma_{c,i}^2)$，其中$\\mu_{c,i}$和$\\sigma_{c,i}^2$分别是第c类样本在第i个属性上取值的均值和方差，则有  \n",
    "$\n",
    "   p(x_i|c)=\\frac{1}{\\sqrt{2\\pi}\\sigma_{c,i}} exp(-\\frac{(x_i-\\mu_{c,i})^2}{2\\sigma_{c,i}^2})\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. 以西瓜数据为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>root</th>\n",
       "      <th>knock</th>\n",
       "      <th>stripp</th>\n",
       "      <th>sto</th>\n",
       "      <th>feel</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>青绿</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>浊响</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>乌黑</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>沉闷</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>乌黑</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>浊响</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>青绿</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>沉闷</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>浅白</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>浊响</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>青绿</td>\n",
       "      <td>稍蜷</td>\n",
       "      <td>浊响</td>\n",
       "      <td>清晰</td>\n",
       "      <td>稍凹</td>\n",
       "      <td>软粘</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>乌黑</td>\n",
       "      <td>稍蜷</td>\n",
       "      <td>浊响</td>\n",
       "      <td>稍糊</td>\n",
       "      <td>稍凹</td>\n",
       "      <td>软粘</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>乌黑</td>\n",
       "      <td>稍蜷</td>\n",
       "      <td>浊响</td>\n",
       "      <td>清晰</td>\n",
       "      <td>稍凹</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>乌黑</td>\n",
       "      <td>稍蜷</td>\n",
       "      <td>沉闷</td>\n",
       "      <td>稍糊</td>\n",
       "      <td>稍凹</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>青绿</td>\n",
       "      <td>硬挺</td>\n",
       "      <td>清脆</td>\n",
       "      <td>清晰</td>\n",
       "      <td>平坦</td>\n",
       "      <td>软粘</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>浅白</td>\n",
       "      <td>硬挺</td>\n",
       "      <td>清脆</td>\n",
       "      <td>模糊</td>\n",
       "      <td>平坦</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>浅白</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>浊响</td>\n",
       "      <td>模糊</td>\n",
       "      <td>平坦</td>\n",
       "      <td>软粘</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>青绿</td>\n",
       "      <td>稍蜷</td>\n",
       "      <td>浊响</td>\n",
       "      <td>稍糊</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>浅白</td>\n",
       "      <td>稍蜷</td>\n",
       "      <td>沉闷</td>\n",
       "      <td>稍糊</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>乌黑</td>\n",
       "      <td>稍蜷</td>\n",
       "      <td>浊响</td>\n",
       "      <td>清晰</td>\n",
       "      <td>稍凹</td>\n",
       "      <td>软粘</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>浅白</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>浊响</td>\n",
       "      <td>模糊</td>\n",
       "      <td>平坦</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>青绿</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>沉闷</td>\n",
       "      <td>稍糊</td>\n",
       "      <td>稍凹</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color root knock stripp sto feel labels\n",
       "0     青绿   蜷缩    浊响     清晰  凹陷   硬滑   good\n",
       "1     乌黑   蜷缩    沉闷     清晰  凹陷   硬滑   good\n",
       "2     乌黑   蜷缩    浊响     清晰  凹陷   硬滑   good\n",
       "3     青绿   蜷缩    沉闷     清晰  凹陷   硬滑   good\n",
       "4     浅白   蜷缩    浊响     清晰  凹陷   硬滑   good\n",
       "5     青绿   稍蜷    浊响     清晰  稍凹   软粘   good\n",
       "6     乌黑   稍蜷    浊响     稍糊  稍凹   软粘   good\n",
       "7     乌黑   稍蜷    浊响     清晰  稍凹   硬滑   good\n",
       "8     乌黑   稍蜷    沉闷     稍糊  稍凹   硬滑    bad\n",
       "9     青绿   硬挺    清脆     清晰  平坦   软粘    bad\n",
       "10    浅白   硬挺    清脆     模糊  平坦   硬滑    bad\n",
       "11    浅白   蜷缩    浊响     模糊  平坦   软粘    bad\n",
       "12    青绿   稍蜷    浊响     稍糊  凹陷   硬滑    bad\n",
       "13    浅白   稍蜷    沉闷     稍糊  凹陷   硬滑    bad\n",
       "14    乌黑   稍蜷    浊响     清晰  稍凹   软粘    bad\n",
       "15    浅白   蜷缩    浊响     模糊  平坦   硬滑    bad\n",
       "16    青绿   蜷缩    沉闷     稍糊  稍凹   硬滑    bad"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../chp03-decisionTree/watermallon.bak\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于测试样例：\n",
    "\n",
    "|  编号   |  色泽  |  根蒂  |  敲声  | 纹理  |  脐部  |  触感  |  好瓜 |\n",
    "|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|\n",
    "|  1  |  青绿  |  蜷缩  |  浊响  |  清晰 |  凹陷  |  硬滑  |  ？ |\n",
    "\n",
    "首先估计先验概率P(c)，显然有：\n",
    "\n",
    "$ \n",
    "        P(好瓜=是)=\\frac{8}{17}\\approx0.471 \\\\\n",
    "        P(好瓜=否)=\\frac{9}{17}\\approx0.529 \\\\\n",
    "$\n",
    "\n",
    "然后，为每个属性估计条件概率：\n",
    "\n",
    "$\n",
    "P(青绿|是)=P(色泽=青绿|好瓜=是)=\\frac{3}{8}=0.375 \\\\\n",
    "P(青绿|否)=P(色泽=青绿|好瓜=否)=\\frac{3}{9}\\approx0.333 \\\\\n",
    "P(蜷缩|是)=P(根蒂=蜷缩|好瓜=是)=\\frac{5}{8}=0.625 \\\\\n",
    "P(蜷缩|否)=P(根蒂=蜷缩|好瓜=否)=\\frac{3}{9}\\approx0.333 \\\\\n",
    "P(浊响|是)=P(敲声=浊响|好瓜=是)=\\frac{6}{8}=0.750 \\\\\n",
    "P(浊响|否)=P(敲声=浊响|好瓜=否)=\\frac{4}{9}\\approx0.444 \\\\\n",
    "P(清晰|是)=P(纹理=清晰|好瓜=是)=\\frac{7}{8}=0.875 \\\\\n",
    "P(清晰|否)=P(纹理=清晰|好瓜=否)=\\frac{2}{9}\\approx0.222 \\\\\n",
    "P(凹陷|是)=P(脐部=凹陷|好瓜=是)=\\frac{6}{8}=0.750 \\\\\n",
    "P(凹陷|否)=P(脐部=凹陷|好瓜=否)=\\frac{2}{9}\\approx0.222 \\\\\n",
    "P(硬滑|是)=P(触感=硬滑|好瓜=是)=\\frac{6}{8}=0.750 \\\\\n",
    "P(硬滑|否)=P(触感=硬滑|好瓜=否)=\\frac{6}{9}\\approx0.667 \\\\\n",
    "$\n",
    "\n",
    "于是有\n",
    " \n",
    "$\n",
    "P(好瓜=是)×P(青绿|是)*P(蜷缩|是)*P(浊响|是)*P(清晰|是)*P(凹陷|是)*P(硬滑|是)\\approx0.0407  \\\\\n",
    "P(好瓜=否)×P(青绿|否)*P(蜷缩|否)*P(浊响|否)*P(清晰|否)*P(凹陷|否)*P(硬滑|否)\\approx0.0008  \\\\\n",
    "$\n",
    "\n",
    "因为0.047>0.0008，所以，朴素贝叶斯分类器将测试样本判别为”好瓜“。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04074966430664063"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.471*0.375*0.625*0.750*0.875*0.750*0.750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008561678034527272"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.529*0.333*0.333*0.444*0.222*0.222*0.667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意**\n",
    "\n",
    "若某个属性值在训练集中没有与某个类同时出现过，则会出现问题，连乘式计算的概率为0.为了避免其他属性携带的信息被训练集中未出现的属性值”抹去“，在估计概率值时通常要进行”平滑“，常用”拉普拉斯修正“。令N表示训练集D中可能的类别数，$N_i$表示第i个属性可能的取值数，则公式可以修正为：\n",
    "\n",
    "$\n",
    "\\hat{P}(c)=\\frac{|D_c|+1}{|D|+N} \\\\\n",
    "\\hat{P}(x_i|c)=\\frac{|D_{c,x_i}|+1}{|D_c|+N_i}\n",
    "$\n",
    "\n",
    "那么上面的例子可以修正为\n",
    "\n",
    "$\n",
    "P(好瓜=是)=\\frac{8+1}{17+2}\\approx0.474 \\\\\n",
    "P(好瓜=否)=\\frac{9+1}{17+2}\\approx0.526 \\\\\n",
    "P(青绿|是)=P(色泽=青绿|好瓜=是)=\\frac{3+1}{8+3}\\approx0.364 \\\\\n",
    "P(青绿|否)=P(色泽=青绿|好瓜=否)=\\frac{3+1}{9+3}\\approx0.333 \\\\\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. 使用贝叶斯分类器进行文本分类\n",
    "《机器学习实战》中基于伯努利模型实现朴素贝叶斯分类器。这种实现方式不考虑词在文档中出现的次数，只考虑出不出现，因此在这个意义上相当于假设词是等权重的。\n",
    "\n",
    "文档转为词向量的过程：\n",
    "1. 统计训练集中所有出现过的单词，将单词加入到一个list中（不含重复单词）记为tlist，tlist长度为n\n",
    "2. 输入一个句子s，并生成一个长度为n的list，如果tlist中位置i的单词可以在s中找到，则相应位置记为1，否则记为0\n",
    "\n",
    "如此可以得到一个句子向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createVocabList(dataSet):\n",
    "    vocaSet = set([])\n",
    "    for doc in dataSet:\n",
    "        vocaSet = vocaSet | set(doc)\n",
    "    return list(vocaSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 0]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def myword2vec(vocabList, inputSet):\n",
    "    returnvec = [0]*len(vocabList)\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            returnvec[vocabList.index(word)]=1\n",
    "        else:\n",
    "            print(\"the word %s is not in my vocabulary!\" % word)\n",
    "    return returnvec\n",
    "\n",
    "myword2vec([\"a\",\"b\",\"c\",\"d\"],(\"a\",\"b\",\"c\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 从词向量计算概率\n",
    "\n",
    "'''\n",
    "trainMatrix : 由训练集组成的句向量矩阵 \n",
    "labels： 标签，数据类型，dataFrame，column名为\"labels\"\n",
    "\n",
    "RETURN：\n",
    "    p: 一个数组，每个数组是一个向量，表示标签对应向量的概率P(w|c_i)\n",
    "    P: 一个字典，标明数据集中每个标签类别的概率\n",
    "    llabelset: 一个数组，有标签集合转化而来，数组中的顺序与p中的值相对应\n",
    "'''\n",
    "def trainNB0(trainMatrix, labels):\n",
    "    # 有n个句子就会有n个向量\n",
    "    numTrainDocs = len(trainMatrix)\n",
    "    # 向量的长度\n",
    "    numWords = len(trainMatrix[0])\n",
    "    labelset = set(labels.labels.values.tolist())\n",
    "    N = len(labelset)\n",
    "    \n",
    "    # 计算出每种类型所占比例\n",
    "    P = {}\n",
    "    llabelset = list(labelset)\n",
    "    print(llabelset)\n",
    "    for i in llabelset:\n",
    "        P[i] = (len(labels[labels.labels==i])+1)/(numTrainDocs+N)\n",
    "    \n",
    "    labellist = labels.labels.values.tolist()\n",
    "    p = {}\n",
    "    numcate = []\n",
    "    denom = []\n",
    "    for i in range(len(llabelset)):\n",
    "        numcate.append(np.ones(numWords))\n",
    "        denom.append(2.0)\n",
    "    \n",
    "    for j in range(len(llabelset)):\n",
    "        for i in range(numTrainDocs):\n",
    "            if labellist[i] == llabelset[j]:\n",
    "                numcate[j] += trainMatrix[i]\n",
    "                denom[j] += sum(trainMatrix[i])\n",
    "                \n",
    "    pvec = []\n",
    "    for i in range(len(llabelset)):\n",
    "        print(numcate[i],denom[i])\n",
    "        pvec.append(np.log(numcate[i]/denom[i]))\n",
    "        \n",
    "    return pvec,P,llabelset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['浊响', '清脆', '凹陷', '稍凹', '平坦', '浅白', '清晰', '稍蜷', '沉闷', '稍糊', '蜷缩', '青绿', '软粘', '硬挺', '硬滑', '乌黑', '模糊']\n",
      "[0, 1]\n",
      "[5. 3. 3. 4. 5. 5. 3. 5. 4. 5. 4. 4. 4. 3. 7. 3. 4.] 56.0\n",
      "[7. 1. 6. 4. 1. 2. 8. 4. 3. 2. 6. 4. 3. 1. 7. 5. 1.] 50.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([array([-2.41591378, -2.9267394 , -2.9267394 , -2.63905733, -2.41591378,\n",
       "         -2.41591378, -2.9267394 , -2.41591378, -2.63905733, -2.41591378,\n",
       "         -2.63905733, -2.63905733, -2.63905733, -2.9267394 , -2.07944154,\n",
       "         -2.9267394 , -2.63905733]),\n",
       "  array([-1.96611286, -3.91202301, -2.12026354, -2.52572864, -3.91202301,\n",
       "         -3.21887582, -1.83258146, -2.52572864, -2.81341072, -3.21887582,\n",
       "         -2.12026354, -2.52572864, -2.81341072, -3.91202301, -1.96611286,\n",
       "         -2.30258509, -3.91202301])],\n",
       " {0: 0.5263157894736842, 1: 0.47368421052631576},\n",
       " [0, 1])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 西瓜数据集\n",
    "\n",
    "train = df.iloc[:,0:-1].values\n",
    "labels = pd.DataFrame(df.iloc[:,-1])\n",
    "labels[labels.labels=='good']=1\n",
    "labels[labels.labels=='bad']=0\n",
    "# labels = np.array(labels)\n",
    "martix = []\n",
    "\n",
    "vocalist = createVocabList(train)\n",
    "print(vocalist)\n",
    "for i in train:\n",
    "    martix.append(myword2vec(vocalist, i))\n",
    "\n",
    "    \n",
    "trainNB0(martix, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "[1. 2. 2. 1. 2. 1. 2. 1. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2.\n",
      " 2. 1. 1. 2. 2. 3. 1. 4.] 26.0\n",
      "[3. 1. 1. 2. 1. 2. 1. 2. 1. 3. 1. 2. 1. 1. 1. 1. 2. 1. 2. 4. 1. 1. 2. 2.\n",
      " 1. 2. 2. 1. 1. 2. 2. 1.] 21.0\n",
      "[array([-3.25809654, -2.56494936, -2.56494936, -3.25809654, -2.56494936,\n",
      "       -3.25809654, -2.56494936, -3.25809654, -2.56494936, -2.56494936,\n",
      "       -2.56494936, -3.25809654, -2.56494936, -2.56494936, -2.56494936,\n",
      "       -2.56494936, -2.56494936, -2.56494936, -3.25809654, -3.25809654,\n",
      "       -2.56494936, -2.56494936, -3.25809654, -2.56494936, -2.56494936,\n",
      "       -3.25809654, -3.25809654, -2.56494936, -2.56494936, -2.15948425,\n",
      "       -3.25809654, -1.87180218]), array([-1.94591015, -3.04452244, -3.04452244, -2.35137526, -3.04452244,\n",
      "       -2.35137526, -3.04452244, -2.35137526, -3.04452244, -1.94591015,\n",
      "       -3.04452244, -2.35137526, -3.04452244, -3.04452244, -3.04452244,\n",
      "       -3.04452244, -2.35137526, -3.04452244, -2.35137526, -1.65822808,\n",
      "       -3.04452244, -3.04452244, -2.35137526, -2.35137526, -3.04452244,\n",
      "       -2.35137526, -2.35137526, -3.04452244, -3.04452244, -2.35137526,\n",
      "       -2.35137526, -3.04452244])] {0: 0.5, 1: 0.5}\n"
     ]
    }
   ],
   "source": [
    "#邮件数据集\n",
    "\n",
    "martixpostingList = [\n",
    "    ['my', 'dog', 'has','flea','problems','help','please'],\n",
    "    ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
    "    ['my', 'dalmation','is','so','cute','I','love','him'],\n",
    "    ['stop','posting','stupid','worthless','garbage'],\n",
    "    ['mr','licks','ate','my','steak','how','to','stop','him'],\n",
    "    ['quit','buying','worthless','dog','food','stupid']\n",
    "]\n",
    "classvec = [0,1,0,1,0,1]\n",
    "\n",
    "classvec=pd.DataFrame(classvec, columns=['labels'])\n",
    "vocablist = createVocabList(postingList)\n",
    "trainMat = []\n",
    "for i in postingList:\n",
    "    trainMat.append(myword2vec(vocablist, i))\n",
    "    \n",
    "p,P,llabelset = trainNB0(trainMat, classvec)\n",
    "print(p,P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "-7.694848072384611\n",
      "1\n",
      "-9.826714493730215\n",
      "0\n",
      "-------------------------------\n",
      "0\n",
      "-7.20934025660291\n",
      "1\n",
      "-4.702750514326955\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 分类函数\n",
    "'''\n",
    "vec2Classfied: 等待分类的向量\n",
    "p: 一个数组，每个数组是一个向量，表示标签对应向量的概率P(w|c_i)\n",
    "P: 一个字典，标明数据集中每个标签类别的概率\n",
    "llabelset: 一个数组，有标签集合转化而来，数组中的顺序与p中的值相对应\n",
    "\n",
    "RETURN:\n",
    "    llabelset[index] 类别\n",
    "'''\n",
    "\n",
    "def classfyNB(vec2Classfied, p, P,llabelset):\n",
    "    result = []\n",
    "    for i in range(len(p)):\n",
    "        print(llabelset[i])\n",
    "        result.append(sum(vec2Classfied*p[i])+np.log(P[llabelset[i]]))\n",
    "        print(result[i])\n",
    "    maxnum = max(result)\n",
    "    index = result.index(maxnum)\n",
    "    return llabelset[index]\n",
    "    \n",
    "    \n",
    "test = [\"love\",'my','dalmation']\n",
    "test2 = ['stupid','garbage']\n",
    "thisDoc = np.array(myword2vec(vocablist, test))\n",
    "print(classfyNB(thisDoc,p,P,llabelset))\n",
    "print(\"-------------------------------\")\n",
    "thisDoc = np.array(myword2vec(vocablist, test2))\n",
    "print(classfyNB(thisDoc,p,P,llabelset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
